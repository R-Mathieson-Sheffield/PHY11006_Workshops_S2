

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Weighted and Non-Linear Regression Analysis &#8212; PHYS11006 - Computing Skills Workshop</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'S2_Wk5_Weighted_and_NonLinear_Regression';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Pandas DataFrames" href="S2_Wk6_Pandas.html" />
    <link rel="prev" title="Take Your Barometer For A Walk!" href="S2_Wk2_Take_Your_Barometer_For_A_Walk.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to PHY11006 Computing Skills
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Autumn Semester Week 1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Wk1_Performing_Calculations_with_Computers_I.html">Performing Calculations with Computers I</a></li>
<li class="toctree-l1"><a class="reference internal" href="Wk1_Measurements_Errors_and_Uncertainty.html">Measurements, Errors and Uncertainty</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Autumn Semester Week 2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Wk2_Performing_Calculations_with_Computers_II.html">Performing Calculations with Computers II</a></li>
<li class="toctree-l1"><a class="reference internal" href="Wk2_Functions_and_Modules.html">Functions and Modules</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Autumn Semester Week 3</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Wk3_Conditional_Statements_and_Loops.html">Conditional Statements and Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="Wk3_Visualising_Data_and_Linear_Regression.html">Visualising Data and Linear Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Autumn Semester Week 4</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Wk4_Simple_Linear_Regression.html">Simple Linear Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Autumn Semester Week 5</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Wk5_Solving_Coding_Problems.html">Solving Coding Problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="Wk5_Artificial_Intelligence.html">Artificial Intelligence (AI)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Autumn Semester Week 6</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Wk6_Computing_Skills_Assessment.html">Computing Skills Assessment</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Spring Semester Week 2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="S2_Wk2_Take_Your_Barometer_For_A_Walk.html">Take Your Barometer For A Walk!</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Spring Semester Week 5</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Weighted and Non-Linear Regression Analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Spring Semester Week 6</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="S2_Wk6_Pandas.html">Pandas DataFrames</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Useful_Functions.html">Useful Functions</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FS2_Wk5_Weighted_and_NonLinear_Regression.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/S2_Wk5_Weighted_and_NonLinear_Regression.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Weighted and Non-Linear Regression Analysis</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-recap">Regression Recap</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-linear-regression">Weighted Linear Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-linear-regression-calculations">Weighted Linear Regression Calculations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-linear-regression-comparison">Weighted Linear Regression Comparison</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-linear-regression">Non-Linear Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-non-linear-regression">Weighted Non-Linear Regression</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-curve-fit">Using Curve_Fit</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#curve-fit-example-weighted-linear-regression">Curve_Fit Example: Weighted Linear Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#starting-estimates">Starting Estimates</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#upper-and-lower-bounds">Upper and Lower Bounds</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#goodness-of-fit">Goodness of Fit</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-chi-2-nu">Calculating <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretting-the-chi-2-nu">Interpretting the <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#activities">Activities</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-fitting">1. Linear Fitting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-gaussian-profile">2. The Gaussian Profile</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-exponential-decay">3. The Exponential Decay</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-power-law">4. The Power Law</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sine-cosine-convolution">5. Sine-Cosine Convolution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#free-session">Free Session</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="weighted-and-non-linear-regression-analysis">
<h1>Weighted and Non-Linear Regression Analysis<a class="headerlink" href="#weighted-and-non-linear-regression-analysis" title="Permalink to this heading">#</a></h1>
<div class="section" id="learning-objectives">
<h2>Learning Objectives<a class="headerlink" href="#learning-objectives" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Understand why we use weighted, non-linear and weighted nonlinear regression analysis.</p></li>
<li><p>Be able to perform weighted, non-linear and weighted nonlinear regression analysis using Python.</p>
<ul>
<li><p>Recall how to define a function.</p></li>
<li><p>Be able to use curve_fit for regression analysis.</p></li>
</ul>
</li>
<li><p>Recall <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span> and use it to describe the “goodness-of-fit”.</p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="regression-recap">
<h2>Regression Recap<a class="headerlink" href="#regression-recap" title="Permalink to this heading">#</a></h2>
<p>In this course so far we have covered lots of essential skills needed for data analysis in the lab setting, however we have been working on a couple of assumptions:</p>
<ol class="arabic simple">
<li><p>The data we are working in has no error bars or the error bars are all the same size.</p></li>
<li><p>The data we are modelling can easily be linearised for us to perform a simple linear regression.</p></li>
</ol>
<p>In reality, it is often the case that one or both of these assumptions are incorrect. In today’s session we are going to look at how we may use Python to perform normal and <em>weighted</em> regression analysis on linear and non-linear datasets.</p>
<p>Before we move on to look at these concepts, you may wish to review the materials from last semester about simple linear regression.</p>
</div>
<hr class="docutils" />
<div class="section" id="weighted-linear-regression">
<h2>Weighted Linear Regression<a class="headerlink" href="#weighted-linear-regression" title="Permalink to this heading">#</a></h2>
<p>As mentioned previously, so far in our linear regression analysis we have considered data that is <em>homoscedasitic</em>. We now want consider how we would modify our regression analysis for data points that have associated errors of differing sizes (<em>hetroscedasitic</em> data).</p>
<p>The plot below shows hetroscedasitic data. The data appears to be linear, but there are some small deviations from linearity. If you were to fit a line of best fit to this data by hand would you want it to lie closer to the data points with small error bars or large error bars?</p>
<p>We would want the data points with the smaller error bars to have a greater weighting in our regression analysis as these values are measured to a higher preision! <strong>We must perform a weighted linear regression!</strong></p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/36a07a93aecb6150fd4c278afc3184bb0ff426415a156bd2941aa452df4ebc82.png" src="_images/36a07a93aecb6150fd4c278afc3184bb0ff426415a156bd2941aa452df4ebc82.png" />
</div>
</div>
<div class="section" id="weighted-linear-regression-calculations">
<h3>Weighted Linear Regression Calculations<a class="headerlink" href="#weighted-linear-regression-calculations" title="Permalink to this heading">#</a></h3>
<p>Now that we know why we would perform a weighted linear regression, we must ask “how do we do this mathematically?”.</p>
<p>First, let’s recall the equations we used in a simple linear regression to determine the gradient and intercept of the line of best fit. These values of gradient and intercept are calculated by minimising the residuals (the discrepency between the model fit and actual data).</p>
<p>The gradient of the line of best fit from a simple linear regression is determined using the equation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-d8b2ce2a-f924-43ee-806f-140bc159532e">
<span class="eqno">(30)<a class="headerlink" href="#equation-d8b2ce2a-f924-43ee-806f-140bc159532e" title="Permalink to this equation">#</a></span>\[\begin{equation}
     m = \frac{N\sum{(x_i \cdot y_i)} - \sum{x_i} \cdot\sum{y_i}}{N\sum{\left(x_i^2\right)} - \sum{\left(x_i\right)}^2},
\end{equation}\]</div>
<p>and the intercept of the line of best fit could be determined using:</p>
<div class="amsmath math notranslate nohighlight" id="equation-88699946-30de-4efc-9a54-58f665b6e8c5">
<span class="eqno">(31)<a class="headerlink" href="#equation-88699946-30de-4efc-9a54-58f665b6e8c5" title="Permalink to this equation">#</a></span>\[\begin{equation}
    c = \frac{\sum{y_i} - m\sum{x_i}}{N}.
\end{equation}\]</div>
<p>If we then want to perform a weighted linear regression, these equations may be modified to include a “<em>weighting factor</em>”, <span class="math notranslate nohighlight">\(w_i\)</span>. The the gradient of the line of best fit from a weighted regression may be determined using the equation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-38ca6fac-62e6-4868-aede-6a58e5726286">
<span class="eqno">(32)<a class="headerlink" href="#equation-38ca6fac-62e6-4868-aede-6a58e5726286" title="Permalink to this equation">#</a></span>\[\begin{equation}
    m = \frac{\sum w_i \sum (w_i x_i y_i) - \sum (w_i x_i) \sum (w_i y_i)}{\sum w_i \sum \left(w_i x_i^2 \right) - \left( \sum (w_i x_i) \right)^2},
\end{equation}\]</div>
<p>and the error associated with this gradient is calculable using:</p>
<div class="amsmath math notranslate nohighlight" id="equation-9f6a356f-5b0a-440b-bb06-8f06f7cafcc8">
<span class="eqno">(33)<a class="headerlink" href="#equation-9f6a356f-5b0a-440b-bb06-8f06f7cafcc8" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \Delta m = \sqrt{\frac{\sum w_i}{\sum w_i \sum \left(w_i x_i^2 \right) - \left( \sum (w_i x_i) \right)^2}}.
\end{equation}\]</div>
<p>The intercept of the line of best fit from a weighted regression is determined using using the equation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-3cf0c839-de4b-4c0b-9172-1ac05391634d">
<span class="eqno">(34)<a class="headerlink" href="#equation-3cf0c839-de4b-4c0b-9172-1ac05391634d" title="Permalink to this equation">#</a></span>\[\begin{equation}
    c = \frac{ \sum (w_i x_i^2) \sum (w_i y_i) - \sum (w_i x_i) \sum (w_i x_i y_i)}{\sum w_i \sum \left(w_i x_i^2\right) - \left( \sum (w_i x_i) \right)^2},
\end{equation}\]</div>
<p>and the error associated with this intercept is calculable using:</p>
<div class="amsmath math notranslate nohighlight" id="equation-351297ed-c5c9-4346-850c-36215ba3156c">
<span class="eqno">(35)<a class="headerlink" href="#equation-351297ed-c5c9-4346-850c-36215ba3156c" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \Delta c = \sqrt{\frac{\sum \left(w_i x_i^2\right)}{\sum w_i \sum \left(w_i x_i^2 \right) - \left( \sum (w_i x_i) \right)^2}}.
\end{equation}\]</div>
<p>In order to evalute these equations, we must first determine the weighting factor for each value. The weighting factor must minimize the impact that data points with large associated error bars have on the overall fit - therefore the weighting factor must be small for large associated uncertainties and large for small associated uncertainties. Accordingly the weighting factor for each data point is defined as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-bb5ff3df-1c15-4fe9-a074-01dea51ef4aa">
<span class="eqno">(36)<a class="headerlink" href="#equation-bb5ff3df-1c15-4fe9-a074-01dea51ef4aa" title="Permalink to this equation">#</a></span>\[\begin{equation}
 w_i = \frac{1}{\Delta y_i^2},
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Delta y_i\)</span> represents the uncertainty associated with a given data point in the y-direction. In other texts, <span class="math notranslate nohighlight">\(\alpha\)</span> is used to represent the uncertainty rather than <span class="math notranslate nohighlight">\(\Delta\)</span>.</p>
</div>
<div class="section" id="weighted-linear-regression-comparison">
<h3>Weighted Linear Regression Comparison<a class="headerlink" href="#weighted-linear-regression-comparison" title="Permalink to this heading">#</a></h3>
<p>Now that we know how to perform a simple linear regression and weighted linear regression, let us compare the difference between the two lines of best fit we get for the data plotted above.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/d4c45beb6e8e49ff4b796eea9123903a90cebfe760f0bfd2727a06bc0b230951.png" src="_images/d4c45beb6e8e49ff4b796eea9123903a90cebfe760f0bfd2727a06bc0b230951.png" />
</div>
</div>
<p>It is clear from looking at this plot that the simple linear regression results in a line of best fit where the distance between the line and any given data point (the residual) has been minimised, but when we take into account the magnitude of thr associated errors, the line of best fit from the weighted regression is much more closely aligned with the data points with smaller associated uncertainties.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="non-linear-regression">
<h2>Non-Linear Regression<a class="headerlink" href="#non-linear-regression" title="Permalink to this heading">#</a></h2>
<p>It is likely that all of the expeirments that you have performed in the experimental labs thus far have required you to be able to fit to a linear dataset. This may have required you to linearise your data by rearranging an equation into a <span class="math notranslate nohighlight">\(y =mx+c\)</span> format which is simple to do in many cases, however in many instances it is difficult to do this. In these circumstances it would be far easier to fit a non-linear model to the data.</p>
<p>A “non-linear model” simply means we are not longer fitting a straight line of best fit to determine the optimal values for the gradient and intercept. Instead, we will be optimising the values of other parameters. For example, if I wanted to fit a model to data that follows a normal distribution, I may fit it using a Gaussian profile:</p>
<div class="amsmath math notranslate nohighlight" id="equation-93b7f8d5-9058-4d6a-bd20-8666b37baccc">
<span class="eqno">(37)<a class="headerlink" href="#equation-93b7f8d5-9058-4d6a-bd20-8666b37baccc" title="Permalink to this equation">#</a></span>\[\begin{equation}
 f(x) = a e^{-\frac{(x-b)^2}{2c^2}},
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(a\)</span> represents the height of the distribution, <span class="math notranslate nohighlight">\(b\)</span> represents the mean value of the distribution, and <span class="math notranslate nohighlight">\(c\)</span> represents the standard deviation of the distribution.</p>
<p>The plot below shows a some generated data (this is a gaussian distribution with additional noise added to make it more representative of the sort of data that may be obtained experimentally). Prior to the noise being added to this data, the Gaussian was defined to have a height of 50, a mean value of 150 and a standard deviation of 25.</p>
<p>Using a non-linear fitting routine, I am able to extract values of the parameters <span class="math notranslate nohighlight">\(a\)</span>, <span class="math notranslate nohighlight">\(b\)</span> and <span class="math notranslate nohighlight">\(c\)</span>. For example:</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<img alt="_images/d8ccf50da76b74fbb1d541cdce2560bf2d45e8ec183942db37b1a798d31e20ba.png" src="_images/d8ccf50da76b74fbb1d541cdce2560bf2d45e8ec183942db37b1a798d31e20ba.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The height of this distribution is equal to:  50.2 +/- 0.7 

The mean value of this distribution is equal to:  150.1 +/- 0.4 

The standard deviation of this distribution is equal to:  25.2 +/- 0.4 
</pre></div>
</div>
</div>
</div>
<div class="section" id="weighted-non-linear-regression">
<h3>Weighted Non-Linear Regression<a class="headerlink" href="#weighted-non-linear-regression" title="Permalink to this heading">#</a></h3>
<p>When fitting the Gaussian above, I have again assumed homoscedasicity, however we can also perform a weighted non-linear regression. The key difference when performing a weighted non-linear and weighted linear regression is that we weight the residuals according to:</p>
<div class="amsmath math notranslate nohighlight" id="equation-6e36de74-1e2e-4b64-81fc-9789c15d602f">
<span class="eqno">(38)<a class="headerlink" href="#equation-6e36de74-1e2e-4b64-81fc-9789c15d602f" title="Permalink to this equation">#</a></span>\[\begin{equation}
R_i = \frac{y_i -y_{model}}{\Delta y_i}.
\end{equation}\]</div>
<p>The fitting proceedure performed again minimises these residuals as was the case for the linear regression.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="using-curve-fit">
<h2>Using Curve_Fit<a class="headerlink" href="#using-curve-fit" title="Permalink to this heading">#</a></h2>
<p>Hopefully you now understanding why we may use weighted and/or non-linear regression analysis. It is time to learn how to perform this analysis easily using Python.</p>
<p><strong>It is imperative that you have an understanding of how to define a function in order to perfrom these new types of regression.</strong> If you are not sure how to do this, review the notes from last semester (Week 2 - Functions and Modules).</p>
<p>Last semester we performed simple linear regression using “<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html">linregress</a>”. Unfortunately, linregress is not sophisticated enough to perform weighted linear regressions. Instead, we are going to use “<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html">curve_fit</a>” from the <a class="reference external" href="https://docs.scipy.org/doc/scipy/tutorial/optimize.html">scipy.optimize</a> library. The name of curve_fit suggests that we use it for non-linear fitting, but in reality we can also use it for linear and weighted regression analysis.</p>
<p><img alt="image, alt = &quot;A screenshot of the scipy.optimize.curve_fit python documentation&quot;" src="_images/Curve_Fit.png" /></p>
<p>Looking at the Curve_Fit documentation, we can see that there are a few arguments that we must provide the function with:</p>
<ul class="simple">
<li><p><strong>The model function</strong>: This is a function that we have defined to model our data, for example if we were fitting a linear dataset, the model function would simply be <span class="math notranslate nohighlight">\(y=mx+c\)</span>. It is also stated that the first arguement in this function must be the independant variable and the other function arguements must be equal to the parameters being optimized (e.g. f(xData, gradient, intercept)).</p></li>
<li><p><strong>The x-Data</strong>: This is simply the array of our independent variables i.e. our x-data.</p></li>
<li><p><strong>The y-Data</strong>: This is is an array of the corresponding dependant variables, for which the curve_fit is going to optimise the model to best represent.</p></li>
<li><p><strong>A p0 Array</strong>: An array of starting estimates of the parameters we are aiming to find optimal values for.  This is an optional arguement, but inclusion of starting estimates can increase the speed of the fitting routine or prevent it from giving up before finding optimized values.</p></li>
<li><p><strong>sigma</strong>: If this is presented as a one-dimentional array, the array should contain the undertainties associated with each y-value. Again, this is an optional arguement but its inclusion allows us to perform weighted regression analysis.</p></li>
</ul>
<hr class="docutils" />
<div class="section" id="curve-fit-example-weighted-linear-regression">
<h3>Curve_Fit Example: Weighted Linear Regression<a class="headerlink" href="#curve-fit-example-weighted-linear-regression" title="Permalink to this heading">#</a></h3>
<p>In this example, I will show you how we can use curve_fit to perform a weighted linear regression. The process for fitting non-linear is exactly the same, with the exception that the function used will represent a different model.</p>
<ol class="arabic simple">
<li><p>Let us import the libraries and tools we are going to use for this analysis:</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">curve_fit</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<ol class="arabic simple" start="2">
<li><p>We must define the function that we are going to model to our data.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">LinearRegression</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">gradient</span><span class="p">,</span> <span class="n">intercept</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">gradient</span><span class="o">*</span><span class="n">xData</span> <span class="o">+</span> <span class="n">intercept</span>
    <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<p>As outlined above, the first arguement in our function is the xData, which is an array containing all of our independent variables. <strong>This must be the first arguement in the function.</strong></p>
<p>The gradient and intercept are the next two arguements in our function. When the function is used in curve_fit, it is these two parameters that will be optimized. If our model had additional parameters that needed optimising, we would simply add these into the function.</p>
<hr class="docutils" />
<ol class="arabic simple" start="3">
<li><p>Next we need some data to actually fit the model too. I am going to use the same linear data used above. Although I have manually added this data, we could just as easily import experimental data into the script from a CSV file.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xData</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">])</span>
<span class="n">yData</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">,</span> <span class="mi">5</span> <span class="p">,</span><span class="mf">5.6</span> <span class="p">,</span><span class="mf">6.6</span><span class="p">,</span> <span class="mf">7.9</span><span class="p">,</span> <span class="mf">8.3</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mf">15.5</span><span class="p">])</span>
<span class="n">yError</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">2.6</span><span class="p">])</span>

<span class="c1"># We can also plot this data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">yData</span><span class="p">,</span> <span class="n">yerr</span> <span class="o">=</span> <span class="n">yError</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;xData&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;yData&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4b5a1cc49c461e004d4e9c071400f42ba13519c7a691786c25cd2070fcc4d52b.png" src="_images/4b5a1cc49c461e004d4e9c071400f42ba13519c7a691786c25cd2070fcc4d52b.png" />
</div>
</div>
<hr class="docutils" />
<ol class="arabic simple" start="4">
<li><p>Finally now we can use curve_fit to determine the optimised model parameters.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">popt</span><span class="p">,</span> <span class="n">pcov</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">,</span> <span class="n">xData</span><span class="p">,</span> <span class="n">yData</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">yError</span><span class="p">,</span> <span class="n">p0</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Let us break down what this line of code does:</p>
<ul class="simple">
<li><p><strong>popt</strong>: This is an array containing our optimised model parameters (<strong>P</strong>arameters <strong>opt</strong>imial = popt). In this case the gradient and intercept of our line of best fit. The first value in this array popt[0] will correspond to the optimised value of the first parameter in the model function e.g the gradient in this case.</p></li>
<li><p><strong>pcov</strong>: This is a covariance array from which we can determine the errors associated with the optimised model parameters. This is outlined in the documenation and the calculation is performed in the code below (perr = np.sqrt(np.diag(pcov))).</p></li>
<li><p><strong>curve_fit</strong>: This is where we have called the curve_fit function.</p></li>
<li><p><strong>LinearRegression</strong>: This is the function we defined above. In this case, it tells curve_fit that we are going to perform a linear regression. If we were optimising a different model, this function would define a different model e.g. a Gaussian Function or an exponential function.</p></li>
<li><p><strong>xData</strong>: This is the x-data that we are feeding into the function.</p></li>
<li><p><strong>yData</strong>: This is the y-data that we are feeding into the function and that the model will be optimised to best represent.</p></li>
<li><p><strong>sigma = yError</strong>: Here we are telling curve_fit which array of values to assign as the errors associated with the y-values to use when performing the weighted regression. If we ommitted this arguement, curve_fit would simply perform an unweighted regression.</p></li>
<li><p><strong>p0</strong>: This is set equal to an array/list of starting estimates for the regression analysis. As the gradient is the first arguement in our function, the first number in the array (1.5) corresponds to the starting estimate for this parameter. As the intercept is the second arguement in our function, the second number in the array (-0.7) corresponds to the starting estimate for this parameter.</p></li>
</ul>
<hr class="docutils" />
<ol class="arabic simple" start="5">
<li><p>Once we have performed the weighted regression analysis, we can output the results and add our line of best fit to our plot:</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Firstly, lets determine the errors associated with our optimised values from pcov.</span>
<span class="c1"># The formula to do this is outlined in the curve_fit documentation.</span>
<span class="n">perr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">pcov</span><span class="p">))</span>

<span class="c1"># Let us print our optimised values and uncertainties:</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The gradient of the line of best fit is: &quot;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">popt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;+/-&quot;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">perr</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The intercept of the line of best fit is: &quot;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%.1f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">popt</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;+/-&quot;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%.1f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">perr</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">yData</span><span class="p">,</span> <span class="n">yerr</span> <span class="o">=</span> <span class="n">yError</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">popt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">xData</span> <span class="o">+</span> <span class="n">popt</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Weighted Regression&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;xData&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;yData&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The gradient of the line of best fit is:  1.10 +/- 0.05 

The intercept of the line of best fit is:  0.1 +/- 0.1 
</pre></div>
</div>
<img alt="_images/b5975597654401d3ce94db7ca9253b1939f60c219d76cbd94f481b71b2d4026d.png" src="_images/b5975597654401d3ce94db7ca9253b1939f60c219d76cbd94f481b71b2d4026d.png" />
</div>
</div>
<p>In the example above, when plotting the line of best fit, the y-values are calculated using:</p>
<div class="math notranslate nohighlight">
\[ popt[0]*xData + popt[1].\]</div>
<p>We did the same thing last semester. Here I have mutliplied each xData point by the optimised gradient (popt[0]) and then added the optimised intercept (popt[1]).</p>
<p>If my model function was more complicated, I could simply call my model function here and feed in the xData and entire popt array. I would do this using a asterisk, for example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">yData</span><span class="p">,</span> <span class="n">yerr</span> <span class="o">=</span> <span class="n">yError</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="o">*</span><span class="n">popt</span><span class="p">),</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Weighted Regression&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;xData&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;yData&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b5975597654401d3ce94db7ca9253b1939f60c219d76cbd94f481b71b2d4026d.png" src="_images/b5975597654401d3ce94db7ca9253b1939f60c219d76cbd94f481b71b2d4026d.png" />
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="starting-estimates">
<h3>Starting Estimates<a class="headerlink" href="#starting-estimates" title="Permalink to this heading">#</a></h3>
<p>In the example above, I performed a relatively simple regression and it was very likely that curve_fit would have been able to determine optimised values for the gradient and intercept without any problems. However, it is often the case that curve_fit will give up before it is able to fit a model to the data. If this happens we must provide starting estimates for curve_fit to begin its optimisation routine at. How do we know what good starting estimates are?</p>
<p><strong>We can plot our starting estimates to see if they make sense!</strong></p>
<p>In the example above, the line of best fit was plotted on the graph by feeding our function into plt.plot with the optimised parameters. To make sensible guesses of what our starting estimates should be we can do the same thing to sanity check that our starting estimates are reasonable. For example, take a look at the code below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Here are my starting estimates to sanity check</span>
<span class="n">GradientEstimate</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">InterceptEstimate</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">yData</span><span class="p">,</span> <span class="n">yerr</span> <span class="o">=</span> <span class="n">yError</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Data&#39;</span><span class="p">)</span>

<span class="c1"># Now I am going to feed in my starting estimates into plt.plot to see if they make sense. </span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">GradientEstimate</span><span class="p">,</span> <span class="n">InterceptEstimate</span><span class="p">)</span>
         <span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Weighted Regression&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;xData&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;yData&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b87c39acfccb8e0330f6e95be2127b5bc5a1109c7f8b7523176f9501e1c95312.png" src="_images/b87c39acfccb8e0330f6e95be2127b5bc5a1109c7f8b7523176f9501e1c95312.png" />
</div>
</div>
<p>It is clear that I have overestimated what the gradient of the line of best fit should be and slightly overestimated what the intercept should be. I can now test more appropriate starting estimates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># I will now change my starting estimates to something more appropriate.</span>
<span class="n">GradientEstimate</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">InterceptEstimate</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">yData</span><span class="p">,</span> <span class="n">yerr</span> <span class="o">=</span> <span class="n">yError</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Data&#39;</span><span class="p">)</span>

<span class="c1"># Now I am going to feed in my starting estimates into plt.plot to see if they make sense. </span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">GradientEstimate</span><span class="p">,</span> <span class="n">InterceptEstimate</span><span class="p">)</span>
         <span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Weighted Regression&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;xData&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;yData&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d773e2c0f5d17e5d80acf1eb0d14f4aa33b522e5216f366356fc39ecefd64f65.png" src="_images/d773e2c0f5d17e5d80acf1eb0d14f4aa33b522e5216f366356fc39ecefd64f65.png" />
</div>
</div>
<p>These starting starting estimates look much more appropriate and can be used in the regression analysis!</p>
<p>This is a great technique for saninty checking that your model and starting estimates are appropriate if your regression analysis does not appear to be working.</p>
</div>
<div class="section" id="upper-and-lower-bounds">
<h3>Upper and Lower Bounds<a class="headerlink" href="#upper-and-lower-bounds" title="Permalink to this heading">#</a></h3>
<p>It is often the case that curve_fit will attempt the regression analysis but be unable to provide realistic values for the model parameters or to perform the fit becasue it requires us to narrow down an appropriate range of inital parameter values to iterate over.</p>
<p>For example, you may know that a parameter you are trying to extract from your data should be positive, but curve_fit fits the data by assigning the parameter an unphysical negative value. In this case we can tell curve_fit that the parameter must be assigned a value that sits between a lower and upper bound.</p>
<p>In order to do this we simply add an additional arguement into curve_fit called “<em>bounds</em>”, which we set equal to the lower and upper values that our parameter(s) could possibly adopt. Take a look at the example below which builds upon the weighted linear regression we performed above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">popt</span><span class="p">,</span> <span class="n">pcov</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">,</span> <span class="n">xData</span><span class="p">,</span> <span class="n">yData</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">yError</span><span class="p">,</span> <span class="n">p0</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7</span><span class="p">],</span> 
                       <span class="n">bounds</span> <span class="o">=</span> <span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">],[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p>Looking at the <em>bounds</em> argument, the lower bounds of the first and second parameters in our function, the gradient and intercept, have been set to <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(-10\)</span>, respectively. Similarly, The upper bounds for both parameters have been set to <span class="math notranslate nohighlight">\(10\)</span>.</p>
<p>If I had additional parameters I wanted to have lower and upper limits for, I would simply add these to the lists of the lower and upper bounds. If I had five parameters to be optimised, but only included two lower and upper bounds, these limits would apply to the first two parameters in our function.</p>
<p><strong>The following activities should not require you to apply upper and lower bounds. These tend to be reserved for more complex models</strong>.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="goodness-of-fit">
<h2>Goodness of Fit<a class="headerlink" href="#goodness-of-fit" title="Permalink to this heading">#</a></h2>
<div class="section" id="calculating-chi-2-nu">
<h3>Calculating <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span><a class="headerlink" href="#calculating-chi-2-nu" title="Permalink to this heading">#</a></h3>
<p>The final thing that I would like you to consider is how we assess the quality of a fit - e.g. is the model we have fit to the data any good?</p>
<p>In order to do this we must calculate the reduced chi-sqaure (pronounced “kai-sqaure”), <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span>, which provides a quantitative measure of whether a model is representative of the data it has been fit to taking into consideration the size of the error bars on the data points.</p>
<p>Before we calculate the <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span> we must calculate <span class="math notranslate nohighlight">\(\chi^2\)</span> (i.e. not reduced). We can do this using the following equation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-dc1bc933-dbc1-4325-bc83-5a48f1420b05">
<span class="eqno">(39)<a class="headerlink" href="#equation-dc1bc933-dbc1-4325-bc83-5a48f1420b05" title="Permalink to this equation">#</a></span>\[\begin{equation}
 \chi^2 = \sum{\frac{\left(y_i-y_i(x) \right) ^2}{\Delta y_i^2}},
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(y_i\)</span> is the measured value of y associated with <span class="math notranslate nohighlight">\(x_i\)</span>, <span class="math notranslate nohighlight">\(y_i(x)\)</span> is the value of y predicted by the model for the given value of <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(\Delta y_i\)</span> is the error associated with our measured value <span class="math notranslate nohighlight">\(y_i\)</span>. To determine <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span>, we must divide our <span class="math notranslate nohighlight">\(\chi^2\)</span> by the number of degrees of freedom, <span class="math notranslate nohighlight">\(\nu\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-a6693c3d-b1bf-4654-b033-bb2ad64c1aa4">
<span class="eqno">(40)<a class="headerlink" href="#equation-a6693c3d-b1bf-4654-b033-bb2ad64c1aa4" title="Permalink to this equation">#</a></span>\[\begin{equation}
 \chi^2_{\nu} = \frac{\chi^2}{\nu}.
\end{equation}\]</div>
<p>To determine the number of degrees of freedom, <span class="math notranslate nohighlight">\(\nu\)</span>, we simply take the number of data points in our sample, <span class="math notranslate nohighlight">\(N\)</span>, and the number of parameters that we are extracting from our model, <span class="math notranslate nohighlight">\(n\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-efdd0ccb-fd1f-4c7a-9084-4ff36f37aa68">
<span class="eqno">(41)<a class="headerlink" href="#equation-efdd0ccb-fd1f-4c7a-9084-4ff36f37aa68" title="Permalink to this equation">#</a></span>\[\begin{equation}
 \nu = N - n.
\end{equation}\]</div>
<p>For example, if fitting a linear model to a dataset with <span class="math notranslate nohighlight">\(10\)</span> data points, we are extracting <span class="math notranslate nohighlight">\(2\)</span> parameters from the model (the gradient and the intercept), therefore the number of degrees of freedom would simply equal <span class="math notranslate nohighlight">\(8\)</span>.</p>
</div>
<div class="section" id="interpretting-the-chi-2-nu">
<h3>Interpretting the <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span><a class="headerlink" href="#interpretting-the-chi-2-nu" title="Permalink to this heading">#</a></h3>
<p>Once <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span> has been determined for a given model and dataset, we are able to gauge if the fit is suitible. We would expect that if the model was representative of the data and the error bars associated with the data points were an appropriate size, <span class="math notranslate nohighlight">\(\chi^2_{\nu} \approx 1\)</span>.
Considering the equation we used to calculate <span class="math notranslate nohighlight">\(\chi^2\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-59222c84-b35f-4ed4-8bc7-7078ec5543fa">
<span class="eqno">(42)<a class="headerlink" href="#equation-59222c84-b35f-4ed4-8bc7-7078ec5543fa" title="Permalink to this equation">#</a></span>\[\begin{equation}
 \chi^2 = \sum{\frac{\left(y_i-y_i(x) \right) ^2}{\Delta y_i^2}},
\end{equation}\]</div>
<p>A larger than 1 value of <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span> can be attributed to two things:</p>
<ul class="simple">
<li><p>The numerator of the equation is large, meaning that their is a large discrepency between the model and measured data (e.g. the model does not represent the trends observed in the data).</p></li>
<li><p>The denominator is small, meaning that the the errors are small (check that they haven’t been underestimated or miscalculated).</p></li>
</ul>
<p>A smaller than 1 value of <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span> can be attributed to:</p>
<ul class="simple">
<li><p>A large denominator, meaning that the errors are large (again, check that they haven’t been overestimated or miscalculated).</p></li>
</ul>
<p>When performing analysis in a lab setting it would be useful to report and comment on the value of <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span> determined - it may provide insight into the limitations of your experiment which then become good points to talk about in your results and discussion section of a report.</p>
<p>The value of <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span> can adopt a value between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(\infty\)</span>. <strong>As a general rule of thumb, we would expect that a good fit would have a <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span> that falls between <span class="math notranslate nohighlight">\(0.25\)</span> and <span class="math notranslate nohighlight">\(4\)</span></strong>.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="activities">
<h2>Activities<a class="headerlink" href="#activities" title="Permalink to this heading">#</a></h2>
<p>Having read through the materials above, I would now like you to put into practise what you have learnt by performing various linear and non-linear fitting (both weighted and non-weighted fits). Data for you to fit models to has been provided on CoCalc. You will need to import this data using an appropriate package.</p>
<div class="section" id="linear-fitting">
<h3>1. Linear Fitting<a class="headerlink" href="#linear-fitting" title="Permalink to this heading">#</a></h3>
<div class="amsmath math notranslate nohighlight" id="equation-5943608c-6121-413d-87a1-7f8453e98dbf">
<span class="eqno">(43)<a class="headerlink" href="#equation-5943608c-6121-413d-87a1-7f8453e98dbf" title="Permalink to this equation">#</a></span>\[\begin{equation}
 y = mx + c
\end{equation}\]</div>
<ol class="arabic simple">
<li><p>Perform both <strong>simple and weighted</strong> linear regressions on Data1.csv and Data2.csv.</p></li>
<li><p>Create a figure containing subplots (one for each dataset) that includes both lines of best fit determined for each dataset.</p></li>
<li><p>Write clear print statements that states the gradients and intercepts (and their associated errors) determined from each regression.</p></li>
<li><p>Calculate the <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span> for the weighted linear regressions.</p></li>
<li><p>Comment on the goodness of fit.</p></li>
</ol>
</div>
<div class="section" id="the-gaussian-profile">
<h3>2. The Gaussian Profile<a class="headerlink" href="#the-gaussian-profile" title="Permalink to this heading">#</a></h3>
<div class="amsmath math notranslate nohighlight" id="equation-fea921d4-b2e8-417a-93f9-9cb6eff1d8ff">
<span class="eqno">(44)<a class="headerlink" href="#equation-fea921d4-b2e8-417a-93f9-9cb6eff1d8ff" title="Permalink to this equation">#</a></span>\[\begin{equation}
 f(x) = a e^{-\frac{(x-b)^2}{2c^2}} + d,
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(a\)</span> represents the height of the distribution, <span class="math notranslate nohighlight">\(b\)</span> represents the mean value of the distribution, <span class="math notranslate nohighlight">\(c\)</span> represents the standard deviation of the distribution and <span class="math notranslate nohighlight">\(d\)</span> represents a baseline of background noise.</p>
<ol class="arabic simple">
<li><p>Define a function for a Gaussian profile and perform a <strong>weighted</strong> non-linear regression to determine the values of <span class="math notranslate nohighlight">\(a\)</span>, <span class="math notranslate nohighlight">\(b\)</span>, <span class="math notranslate nohighlight">\(c\)</span> and <span class="math notranslate nohighlight">\(d\)</span> using on Data3.csv.</p></li>
<li><p>Create a high-quality plot that shows the data and optimised model fit.</p></li>
<li><p>Write a clear print statement that states the values of the optimised parameters and their associated errors.</p></li>
<li><p>Calculate the <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span> for the Gaussian fit.</p></li>
<li><p>Comment on the goodness of fit.</p></li>
</ol>
</div>
<div class="section" id="the-exponential-decay">
<h3>3. The Exponential Decay<a class="headerlink" href="#the-exponential-decay" title="Permalink to this heading">#</a></h3>
<div class="amsmath math notranslate nohighlight" id="equation-93caaeb2-68b0-45a8-9c6e-4888e4b539b7">
<span class="eqno">(45)<a class="headerlink" href="#equation-93caaeb2-68b0-45a8-9c6e-4888e4b539b7" title="Permalink to this equation">#</a></span>\[\begin{equation}
 N = N_0 e^{-\lambda t} + b,
\end{equation}\]</div>
<ol class="arabic simple">
<li><p>Define a function for the exponential decay and perform a <strong>weighted</strong> non-linear regression to determine the values of <span class="math notranslate nohighlight">\(N_0\)</span>, <span class="math notranslate nohighlight">\(\lambda\)</span> and <span class="math notranslate nohighlight">\(b\)</span> using Data4.csv.</p></li>
<li><p>Create a high-quality plot that shows the data and optimised model fit.</p></li>
<li><p>Write a clear print statement that states the values of the optimised parameters and their associated errors.</p></li>
<li><p>Calculate the <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span> for the exponential fit.</p></li>
<li><p>Comment on the goodness of fit.</p></li>
</ol>
</div>
<div class="section" id="the-power-law">
<h3>4. The Power Law<a class="headerlink" href="#the-power-law" title="Permalink to this heading">#</a></h3>
<div class="amsmath math notranslate nohighlight" id="equation-a4ca683d-1cfa-45e5-9eaf-c2656d5a7537">
<span class="eqno">(46)<a class="headerlink" href="#equation-a4ca683d-1cfa-45e5-9eaf-c2656d5a7537" title="Permalink to this equation">#</a></span>\[\begin{equation}
f(x) = x^n + b
\end{equation}\]</div>
<ol class="arabic simple">
<li><p>Define a function for the power law and perform a non-linear regression to determine the values of <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(b\)</span> using Data5.csv.</p></li>
<li><p>Create a high-quality plot that shows the data and optimised model fit.</p></li>
<li><p>Write a clear print statement that states the values of the optimised parameters and their associated errors.</p></li>
</ol>
</div>
<div class="section" id="sine-cosine-convolution">
<h3>5. Sine-Cosine Convolution<a class="headerlink" href="#sine-cosine-convolution" title="Permalink to this heading">#</a></h3>
<div class="amsmath math notranslate nohighlight" id="equation-2bbf2e42-3083-438d-99f1-9bc3bf37da53">
<span class="eqno">(47)<a class="headerlink" href="#equation-2bbf2e42-3083-438d-99f1-9bc3bf37da53" title="Permalink to this equation">#</a></span>\[\begin{equation}
f(x) = A(sin(nx) + cos(mx))
\end{equation}\]</div>
<ol class="arabic simple">
<li><p>Define a function for the given wave-function and perform a non-linear regression to determine the values of <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(m\)</span> using Data6.csv.</p></li>
<li><p>Create a high-quality plot that shows the data and optimised model fit.</p></li>
<li><p>Write a clear print statement that states the values of the optimised parameters and their associated errors.</p></li>
</ol>
</div>
</div>
<div class="section" id="free-session">
<h2>Free Session<a class="headerlink" href="#free-session" title="Permalink to this heading">#</a></h2>
<p>Once you have reviewed the notes above and completed the associated activities, you are welcome to use this session as you please.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="S2_Wk2_Take_Your_Barometer_For_A_Walk.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Take Your Barometer For A Walk!</p>
      </div>
    </a>
    <a class="right-next"
       href="S2_Wk6_Pandas.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Pandas DataFrames</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-recap">Regression Recap</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-linear-regression">Weighted Linear Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-linear-regression-calculations">Weighted Linear Regression Calculations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-linear-regression-comparison">Weighted Linear Regression Comparison</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-linear-regression">Non-Linear Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-non-linear-regression">Weighted Non-Linear Regression</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-curve-fit">Using Curve_Fit</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#curve-fit-example-weighted-linear-regression">Curve_Fit Example: Weighted Linear Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#starting-estimates">Starting Estimates</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#upper-and-lower-bounds">Upper and Lower Bounds</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#goodness-of-fit">Goodness of Fit</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-chi-2-nu">Calculating <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretting-the-chi-2-nu">Interpretting the <span class="math notranslate nohighlight">\(\chi^2_{\nu}\)</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#activities">Activities</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-fitting">1. Linear Fitting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-gaussian-profile">2. The Gaussian Profile</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-exponential-decay">3. The Exponential Decay</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-power-law">4. The Power Law</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sine-cosine-convolution">5. Sine-Cosine Convolution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#free-session">Free Session</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Ross Mathieson
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>